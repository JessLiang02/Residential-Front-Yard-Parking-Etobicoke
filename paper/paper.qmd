---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....

The structure of this paper is organized as follows. @sec-data introduces the data sources and the key variables utilized in our analysis, offering a comprehensive overview of the dataset and how the variables were selected. @sec-model outlines the modeling strategy, including the linear regression framework, along with its underlying assumptions and the rationale for the inclusion of specific predictors like state, pollster, and poll score. @sec-results presents the model results, emphasizing the significant factors driving Trumpâ€™s percentage support and analyzing any diagnostic issues such as heteroscedasticity and residual normality. @sec-discussion delves into the broader implications of our findings, discussing their relevance to polling accuracy, potential biases, and offering suggestions for future research to enhance predictive modeling in political contexts.




# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR].... Our data [@shelter].... Following @tellingstories, we consider...

For this analysis, we employed the R programming language [@citeR] to examine polling data on public sentiment before the election. Our dataset, sourced from FiveThirtyEight [@fivethirtyeight2024], offers a detailed snapshot of evolving public opinion. We explored key influences on percentage support, including the timing of the polls, pollster characteristics, and geographic differences.

Several `R` packages were instrumental in performing data manipulation, modeling, and visualization. `Tidyverse` was the backbone for organizing and analyzing the data efficiently, allowing seamless integration of multiple tasks [@thereferencecanbewhatever]. `Here` streamlined file path handling, ensuring smooth data access across systems [@citehere]. We relied on `Janitor` for robust data cleaning, helping identify and fix potential inconsistencies [@citejanitor], and `rstanarm` facilitated the Bayesian stastistical modeling [@rstanarm]. Additionally, `Arrow` provided fast and memory-efficient access to large datasets, a critical factor for managing extensive polling data [@citearrow]. The structure of the codebase and workflow adhered to the best practices outlined in @tellingstories.

Overview text

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.


@fig-type 

```{r}
#| label: fig-type
#| fig-cap: Bills of penguins
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_parquet(here::here("data/02-analysis_data/analysis_data.parquet"))

# Summarize morespace percentages by parking type
morespace_vs_parking <- analysis_data %>%
  group_by(parking_type, morespace) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(percentage = count / sum(count) * 100)

# Barplot: Morespace (%) vs. Parking Type
ggplot(morespace_vs_parking, aes(x = parking_type, y = percentage, fill = factor(morespace))) +
  geom_bar(stat = "identity", position = "fill") +
  labs(
    x = "Parking Type",
    y = "Percentage (%)",
    fill = "More than 1 parking space"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

@fig-ward provides a visual comparison of the proportion of "Morespace" responses across wards. The y-axis represents the percentage, scaled from 0% to 100%, while the x-axis shows the wards under study. The red portion of each bar indicates the percentage of "No" responses, whereas the blue portion indicates the percentage of "Yes" responses. From the chart, it is evident that "No" dominates the responses in all wards, with "Yes" contributing only a small proportion across the board. The distribution highlights the consistency in the prevalence of "No" responses irrespective of ward, with slight variations in the proportion of "Yes" responses between different wards. This visualization underscores potential patterns or uniformity in "Morespace" responses within the study area.

```{r}
#| label: fig-ward
#| fig-cap: The figure illustrates the distribution of "More than 1 parking space" (Yes/No) as a percentage across various wards. Each bar represents a ward, and the height of the stacked segments within each bar corresponds to the proportion of responses for "Morespace." The responses "No" (red) and "Yes" (blue) sum to 100% for each ward.
#| echo: false
#| warning: false
#| message: false

# Summarize morespace percentages by ward
morespace_vs_ward <- analysis_data %>%
  group_by(ward, morespace) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(percentage = count / sum(count) * 100)

# Barplot: Morespace (%) vs. Ward
ggplot(morespace_vs_ward, aes(x = ward, y = percentage, fill = factor(morespace))) +
  geom_bar(stat = "identity", position = "fill") +
  labs(
    x = "Ward",
    y = "Percentage (%)",
    fill = "More than 1 parking space"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Talk way more about it. 

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.








# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```



\newpage


# References


